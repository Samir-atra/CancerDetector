{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Samir-atra/CancerDetector/blob/main/Cancer_Detector/Transfer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PAFBOomjSbe8"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL.Image\n",
        "from PIL import ImageOps\n",
        "import PIL\n",
        "import pathlib\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime\n",
        "import tensorboard\n",
        "import IPython\n",
        "import sklearn\n",
        "import cv2\n",
        "import subprocess\n",
        "import sys\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMQQCq3WSggX",
        "outputId": "d1e26683-3862-4644-a319-90b3c25615e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mounting google drive for training in google co lab\n",
        "\n",
        "from google.colab import drive             \n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9RolTK1SbfB",
        "outputId": "368f717e-9eae-4a9c-85f9-110187550b21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8582 files belonging to 4 classes.\n",
            "Using 6866 files for training.\n",
            "Found 8582 files belonging to 4 classes.\n",
            "Using 1716 files for validation.\n",
            "Found 1705 files belonging to 4 classes.\n",
            "time elapsed =  31.0553879737854\n"
          ]
        }
      ],
      "source": [
        "# Dataset loading\n",
        "\n",
        "data_path = pathlib.Path('/content/drive/MyDrive/archiveX3/Training/')\n",
        "\n",
        "data_path_test = pathlib.Path('/content/drive/MyDrive/archiveX3/Testing/')\n",
        "AUTOTUNE=tf.data.AUTOTUNE\n",
        "\n",
        "start = time.time()\n",
        "dataset_path = tf.keras.utils.image_dataset_from_directory(        # Training dataset\n",
        "    data_path,\n",
        "    labels= 'inferred',\n",
        "    validation_split=0.2,\n",
        "    subset='training',\n",
        "    seed= 1,\n",
        "    batch_size=5,\n",
        "    image_size=(299, 299),\n",
        "    color_mode=\"rgb\",\n",
        "    shuffle=True)#.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "dataset_path_val = tf.keras.utils.image_dataset_from_directory(      #Validation dataset\n",
        "    data_path,\n",
        "    labels= 'inferred',\n",
        "    validation_split=0.2,\n",
        "    subset='validation',\n",
        "    seed= 2,\n",
        "    batch_size=5,\n",
        "    image_size=(299, 299),\n",
        "    color_mode=\"rgb\",\n",
        "    shuffle=True)#.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "dataset_path_test = tf.keras.utils.image_dataset_from_directory(      # Testing dataset\n",
        "    data_path_test,\n",
        "    labels= 'inferred',\n",
        "    seed= 3,\n",
        "    batch_size=5,\n",
        "    image_size=(299, 299),\n",
        "    color_mode=\"rgb\",\n",
        "    shuffle=True)#.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "end = time.time()\n",
        "print(\"time elapsed = \", (end - start))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7A2g8M1BSbfF"
      },
      "outputs": [],
      "source": [
        "# catch and prefetch for shorter training time\n",
        "\n",
        "# AUTOTUNE=tf.data.AUTOTUNE\n",
        "# dataset_path = dataset_path.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "# dataset_path_val = dataset_path_val.cache().prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "qh3RFKFWSbfG",
        "outputId": "f91077f0-f7a5-445d-b9c0-ecea79ac0ee1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87910968/87910968 [==============================] - 5s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# downloading the weights oft the base model\n",
        "\n",
        "base_model = tf.keras.applications.inception_v3.InceptionV3(\n",
        "    input_shape = (299, 299, 3),\n",
        "    include_top = False, \n",
        "    weights = \"imagenet\"                  \n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7TQ9YrgSbfH",
        "outputId": "1bdadee2-e01a-4d80-a4a0-e926cc4a91e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ],
      "source": [
        "#saving the downloaded base_model \n",
        "\n",
        "saving_path = pathlib.Path('/content/drive/MyDrive/archiveX3/SavedBaseModel.h5')\n",
        "\n",
        "base_model.save(saving_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lN_3As-oSbfJ",
        "outputId": "2e36c495-bd50-4013-e3f7-050ff22130fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f8b001161f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f8b001161f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1374/1374 [==============================] - 2122s 2s/step - loss: 3.3157 - accuracy: 0.7850 - val_loss: 2.9318 - val_accuracy: 0.8875\n",
            "Epoch 2/15\n",
            "1374/1374 [==============================] - 476s 346ms/step - loss: 2.8405 - accuracy: 0.8640 - val_loss: 2.5305 - val_accuracy: 0.9254\n",
            "Epoch 3/15\n",
            "1374/1374 [==============================] - 475s 346ms/step - loss: 2.4715 - accuracy: 0.8874 - val_loss: 2.2540 - val_accuracy: 0.9038\n",
            "Epoch 4/15\n",
            "1374/1374 [==============================] - 475s 345ms/step - loss: 2.1595 - accuracy: 0.8988 - val_loss: 1.8942 - val_accuracy: 0.9551\n",
            "Epoch 5/15\n",
            "1374/1374 [==============================] - 477s 347ms/step - loss: 1.8430 - accuracy: 0.9197 - val_loss: 1.7265 - val_accuracy: 0.9149\n",
            "Epoch 6/15\n",
            "1374/1374 [==============================] - 476s 347ms/step - loss: 1.5907 - accuracy: 0.9238 - val_loss: 1.4597 - val_accuracy: 0.9330\n",
            "Epoch 7/15\n",
            "1374/1374 [==============================] - 475s 346ms/step - loss: 1.3798 - accuracy: 0.9241 - val_loss: 1.2363 - val_accuracy: 0.9394\n",
            "Epoch 8/15\n",
            "1374/1374 [==============================] - 474s 345ms/step - loss: 1.1830 - accuracy: 0.9297 - val_loss: 1.0756 - val_accuracy: 0.9441\n",
            "Epoch 9/15\n",
            "1374/1374 [==============================] - 473s 344ms/step - loss: 1.0208 - accuracy: 0.9326 - val_loss: 0.9347 - val_accuracy: 0.9429\n",
            "Epoch 10/15\n",
            "1374/1374 [==============================] - 509s 371ms/step - loss: 0.8864 - accuracy: 0.9345 - val_loss: 0.7736 - val_accuracy: 0.9540\n",
            "Epoch 11/15\n",
            "1374/1374 [==============================] - 510s 371ms/step - loss: 0.7617 - accuracy: 0.9410 - val_loss: 0.7057 - val_accuracy: 0.9534\n",
            "Epoch 12/15\n",
            "1374/1374 [==============================] - 488s 355ms/step - loss: 0.6797 - accuracy: 0.9374 - val_loss: 0.5645 - val_accuracy: 0.9714\n",
            "Epoch 13/15\n",
            "1374/1374 [==============================] - 481s 350ms/step - loss: 0.5870 - accuracy: 0.9476 - val_loss: 0.6028 - val_accuracy: 0.9126\n",
            "Epoch 14/15\n",
            "1374/1374 [==============================] - 486s 354ms/step - loss: 0.5247 - accuracy: 0.9471 - val_loss: 0.4469 - val_accuracy: 0.9703\n",
            "Epoch 15/15\n",
            "1374/1374 [==============================] - 491s 357ms/step - loss: 0.4822 - accuracy: 0.9441 - val_loss: 0.3959 - val_accuracy: 0.9755\n",
            "341/341 [==============================] - 630s 2s/step - loss: 0.7395 - accuracy: 0.9015\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 299, 299, 3)]     0         \n",
            "                                                                 \n",
            " sequential (Sequential)     (None, 299, 299, 3)       0         \n",
            "                                                                 \n",
            " inception_v3 (Functional)   (None, 8, 8, 2048)        21802784  \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 2048)             0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1024)              2098176   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 512)               524800    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 512)               262656    \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 4)                 1028      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 24,820,772\n",
            "Trainable params: 3,017,988\n",
            "Non-trainable params: 21,802,784\n",
            "_________________________________________________________________\n",
            "Epoch 16/30\n",
            "1374/1374 [==============================] - 586s 416ms/step - loss: 0.4797 - accuracy: 0.9390 - val_loss: 0.3448 - val_accuracy: 0.9854\n",
            "Epoch 17/30\n",
            "1374/1374 [==============================] - 563s 410ms/step - loss: 0.3562 - accuracy: 0.9806 - val_loss: 0.3211 - val_accuracy: 0.9907\n",
            "Epoch 18/30\n",
            "1374/1374 [==============================] - 551s 401ms/step - loss: 0.3282 - accuracy: 0.9859 - val_loss: 0.3060 - val_accuracy: 0.9895\n",
            "Epoch 19/30\n",
            "1374/1374 [==============================] - 552s 402ms/step - loss: 0.3022 - accuracy: 0.9904 - val_loss: 0.3061 - val_accuracy: 0.9860\n",
            "Epoch 20/30\n",
            "1374/1374 [==============================] - 554s 403ms/step - loss: 0.2843 - accuracy: 0.9907 - val_loss: 0.2624 - val_accuracy: 0.9977\n",
            "Epoch 21/30\n",
            "1374/1374 [==============================] - 555s 404ms/step - loss: 0.2528 - accuracy: 0.9950 - val_loss: 0.5684 - val_accuracy: 0.9073\n",
            "Epoch 22/30\n",
            "1374/1374 [==============================] - 556s 404ms/step - loss: 0.2382 - accuracy: 0.9926 - val_loss: 0.2379 - val_accuracy: 0.9889\n",
            "Epoch 23/30\n",
            "1374/1374 [==============================] - 553s 402ms/step - loss: 0.2086 - accuracy: 0.9972 - val_loss: 0.1997 - val_accuracy: 0.9971\n",
            "Epoch 24/30\n",
            "1374/1374 [==============================] - 556s 405ms/step - loss: 0.1859 - accuracy: 0.9975 - val_loss: 0.1775 - val_accuracy: 0.9971\n",
            "Epoch 25/30\n",
            "1374/1374 [==============================] - 577s 420ms/step - loss: 0.1520 - accuracy: 1.0000 - val_loss: 0.1484 - val_accuracy: 0.9977\n",
            "Epoch 26/30\n",
            "1374/1374 [==============================] - 548s 399ms/step - loss: 0.1187 - accuracy: 1.0000 - val_loss: 0.1122 - val_accuracy: 0.9971\n",
            "Epoch 27/30\n",
            "1374/1374 [==============================] - 550s 400ms/step - loss: 0.1173 - accuracy: 0.9902 - val_loss: 0.0941 - val_accuracy: 0.9965\n",
            "Epoch 28/30\n",
            "1374/1374 [==============================] - 551s 401ms/step - loss: 0.0868 - accuracy: 0.9972 - val_loss: 0.1360 - val_accuracy: 0.9779\n",
            "Epoch 29/30\n",
            "1374/1374 [==============================] - 549s 400ms/step - loss: 0.0887 - accuracy: 0.9943 - val_loss: 0.0794 - val_accuracy: 0.9977\n",
            "Epoch 30/30\n",
            "1374/1374 [==============================] - 551s 401ms/step - loss: 0.0738 - accuracy: 0.9988 - val_loss: 0.0733 - val_accuracy: 0.9988\n",
            "341/341 [==============================] - 59s 172ms/step - loss: 0.4334 - accuracy: 0.9537\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 299, 299, 3)]     0         \n",
            "                                                                 \n",
            " sequential (Sequential)     (None, 299, 299, 3)       0         \n",
            "                                                                 \n",
            " inception_v3 (Functional)   (None, 8, 8, 2048)        21802784  \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 2048)             0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1024)              2098176   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 512)               524800    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 512)               262656    \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 4)                 1028      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 24,820,772\n",
            "Trainable params: 24,769,124\n",
            "Non-trainable params: 51,648\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 102). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "#Model\n",
        "\n",
        "model_path = pathlib.Path('/content/drive/MyDrive/archiveX3/SavedBaseModel.h5')\n",
        "\n",
        "base_model = tf.keras.models.load_model(model_path)                 #Loading base_model\n",
        "\n",
        "base_model.trainable = False                                        # Setting the model as non-trainable\n",
        "\n",
        "rescaling = tf.keras.Sequential([                                        \n",
        "  tf.keras.layers.Rescaling(scale=1 / 127.5, offset=-1)             # Rescaling to (1, -1) range required for inceptionV3 model\n",
        "])\n",
        "augmentation = tf.keras.Sequential([                                # Applying augmentations o the images\n",
        "   tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "   tf.keras.layers.RandomRotation(0.2)\n",
        "])\n",
        "\n",
        "inputs = tf.keras.Input(shape=(299, 299, 3))\n",
        "# x = augmentation(inputs)\n",
        "x = rescaling(inputs)\n",
        "x = base_model(x)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = tf.keras.layers.Dense(1024, activation='ELU', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)     # Neurons numbers and activation functions based on testing and choosing the one with best results\n",
        "x = tf.keras.layers.Dropout(0.2)(x)\n",
        "x = tf.keras.layers.Dense(512, activation='ELU', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)     # Regularizing and Dropout to avoid overfitting\n",
        "x = tf.keras.layers.Dropout(0.2)(x)\n",
        "x = tf.keras.layers.Dense(512, activation='ELU', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
        "x = tf.keras.layers.Dropout(0.2)(x)\n",
        "x = tf.keras.layers.Dense(256, activation='ELU', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
        "x = tf.keras.layers.Dropout(0.2)(x)\n",
        "outputs = tf.keras.layers.Dense(4, activation='softmax')(x)                   # \"softmax\" in the final layer for decision making\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "\n",
        "model.compile(\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate = 0.0001),        # compiling with low learning rate\n",
        "    loss=tf.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics=['accuracy'],\n",
        "    run_eagerly = True)                                               \n",
        "\n",
        "model.fit(                                                               # fitting the whole model for non-trainable base\n",
        "    dataset_path,\n",
        "    epochs=15,   \n",
        "    validation_data = dataset_path_val)\n",
        "    #verbose = 1)\n",
        "\n",
        "\n",
        "model.evaluate(dataset_path_test, batch_size=5, verbose=1)               # evaluating using the test dataset \n",
        "\n",
        "model.summary()\n",
        "\n",
        "base_model.trainable = True                                           # switching the base_model to trainable\n",
        "\n",
        "for layer in base_model.layers:                                       # Swtching all batchnormalization layer of the base_model to non-trainable to not lose weights\n",
        "  if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate = 0.00001),    # compiling the model with a trainable base_model\n",
        "    loss=tf.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics=['accuracy'],\n",
        "    run_eagerly = True)\n",
        "\n",
        "model.fit(                                                            # fitting for another 10 epochs starting where the non-trainable ended\n",
        "    dataset_path,\n",
        "    epochs=30,         \n",
        "    initial_epoch=15,                \n",
        "    validation_data = dataset_path_val)\n",
        "    #verbose = 1)\n",
        "\n",
        "model.evaluate(dataset_path_test, batch_size=5, verbose=1)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "saving_path = pathlib.Path('/content/drive/MyDrive/archiveX3/SavedModelWithFT/')\n",
        "\n",
        "tf.keras.models.save_model(model,                                     # saving the fully trained model\n",
        "                           saving_path,\n",
        "                           overwrite=True,\n",
        "                           save_format='tf'\n",
        "                           )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJLujUU6xr9G"
      },
      "source": [
        "May find a sample trained model at:  https://drive.google.com/drive/folders/1MsQzyfIj4JxdUIpP_EftdTRvWjm0YY8A?usp=sharing"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Transfer.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.7 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "d4de0671d8054c88a8842951ed8f6115b974e2e5b39cbc2553be5a6678282e63"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}