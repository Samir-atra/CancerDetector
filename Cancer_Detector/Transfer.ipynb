{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Samir-atra/CancerDetector/blob/main/Cancer_Detector/Transfer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PAFBOomjSbe8"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import pathlib\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime\n",
        "import tensorboard\n",
        "import IPython\n",
        "import sklearn\n",
        "import cv2\n",
        "import sys\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMQQCq3WSggX",
        "outputId": "0ab6c81f-5130-42de-dd4d-fe62c6689d54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mounting google drive for training in google co lab\n",
        "\n",
        "from google.colab import drive             \n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9RolTK1SbfB",
        "outputId": "02347fb2-b1f1-4be8-808b-7223d504bbd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8582 files belonging to 4 classes.\n",
            "Using 6866 files for training.\n",
            "Found 8582 files belonging to 4 classes.\n",
            "Using 1716 files for validation.\n",
            "Found 1705 files belonging to 4 classes.\n",
            "time elapsed =  37.107048749923706\n"
          ]
        }
      ],
      "source": [
        "# Dataset loading\n",
        "\n",
        "data_path = pathlib.Path('/content/drive/MyDrive/archiveX3/Training/')\n",
        "\n",
        "data_path_test = pathlib.Path('/content/drive/MyDrive/archiveX3/Testing/')\n",
        "AUTOTUNE=tf.data.AUTOTUNE\n",
        "\n",
        "start = time.time()\n",
        "dataset_path = tf.keras.utils.image_dataset_from_directory(        # Training dataset\n",
        "    data_path,\n",
        "    labels= 'inferred',\n",
        "    validation_split=0.2,\n",
        "    subset='training',\n",
        "    seed= 1,\n",
        "    batch_size=5,\n",
        "    image_size=(299, 299),\n",
        "    color_mode=\"rgb\",\n",
        "    shuffle=True)#.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "dataset_path_val = tf.keras.utils.image_dataset_from_directory(      #Validation dataset\n",
        "    data_path,\n",
        "    labels= 'inferred',\n",
        "    validation_split=0.2,\n",
        "    subset='validation',\n",
        "    seed= 2,\n",
        "    batch_size=5,\n",
        "    image_size=(299, 299),\n",
        "    color_mode=\"rgb\",\n",
        "    shuffle=True)#.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "dataset_path_test = tf.keras.utils.image_dataset_from_directory(      # Testing dataset\n",
        "    data_path_test,\n",
        "    labels= 'inferred',\n",
        "    seed= 3,\n",
        "    batch_size=5,\n",
        "    image_size=(299, 299),\n",
        "    color_mode=\"rgb\",\n",
        "    shuffle=True)#.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "end = time.time()\n",
        "print(\"time elapsed = \", (end - start))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7A2g8M1BSbfF"
      },
      "outputs": [],
      "source": [
        "# catch and prefetch for shorter training time\n",
        "\n",
        "# AUTOTUNE=tf.data.AUTOTUNE\n",
        "# dataset_path = dataset_path.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "# dataset_path_val = dataset_path_val.cache().prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "qh3RFKFWSbfG",
        "outputId": "74b05b9f-fb80-4fce-84db-ea8cc680aa44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87910968/87910968 [==============================] - 5s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# downloading the weights oft the base model\n",
        "\n",
        "base_model = tf.keras.applications.inception_v3.InceptionV3(\n",
        "    input_shape = (299, 299, 3),\n",
        "    include_top = False, \n",
        "    weights = \"imagenet\"                  \n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7TQ9YrgSbfH",
        "outputId": "4cbfc5ee-6e98-4296-f8ce-a12727192094"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ],
      "source": [
        "#saving the downloaded base_model \n",
        "\n",
        "saving_path = pathlib.Path('/content/drive/MyDrive/archiveX3/SavedBaseModel.h5')\n",
        "\n",
        "base_model.save(saving_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lN_3As-oSbfJ",
        "outputId": "f5b73da4-da6c-4864-8f86-8802617bbb20"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/12\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f16855b23a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f16855b23a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1374/1374 [==============================] - 2059s 1s/step - loss: 2.4585 - accuracy: 0.7250 - val_loss: 2.1829 - val_accuracy: 0.8625\n",
            "Epoch 2/12\n",
            "1374/1374 [==============================] - 468s 340ms/step - loss: 2.1588 - accuracy: 0.8526 - val_loss: 2.0665 - val_accuracy: 0.8910\n",
            "Epoch 3/12\n",
            "1374/1374 [==============================] - 471s 343ms/step - loss: 2.0596 - accuracy: 0.8772 - val_loss: 1.9976 - val_accuracy: 0.9050\n",
            "Epoch 4/12\n",
            "1374/1374 [==============================] - 468s 341ms/step - loss: 1.9918 - accuracy: 0.8946 - val_loss: 1.9238 - val_accuracy: 0.9219\n",
            "Epoch 5/12\n",
            "1374/1374 [==============================] - 469s 342ms/step - loss: 1.9309 - accuracy: 0.9053 - val_loss: 1.8702 - val_accuracy: 0.9307\n",
            "Epoch 6/12\n",
            "1374/1374 [==============================] - 469s 341ms/step - loss: 1.8729 - accuracy: 0.9147 - val_loss: 1.8190 - val_accuracy: 0.9394\n",
            "Epoch 7/12\n",
            "1374/1374 [==============================] - 466s 339ms/step - loss: 1.8322 - accuracy: 0.9238 - val_loss: 1.7789 - val_accuracy: 0.9446\n",
            "Epoch 8/12\n",
            "1374/1374 [==============================] - 466s 339ms/step - loss: 1.7874 - accuracy: 0.9295 - val_loss: 1.7354 - val_accuracy: 0.9487\n",
            "Epoch 9/12\n",
            "1374/1374 [==============================] - 467s 340ms/step - loss: 1.7385 - accuracy: 0.9356 - val_loss: 1.6938 - val_accuracy: 0.9510\n",
            "Epoch 10/12\n",
            "1374/1374 [==============================] - 466s 339ms/step - loss: 1.6976 - accuracy: 0.9425 - val_loss: 1.6620 - val_accuracy: 0.9528\n",
            "Epoch 11/12\n",
            "1374/1374 [==============================] - 467s 340ms/step - loss: 1.6619 - accuracy: 0.9451 - val_loss: 1.6259 - val_accuracy: 0.9575\n",
            "Epoch 12/12\n",
            "1374/1374 [==============================] - 468s 340ms/step - loss: 1.6208 - accuracy: 0.9508 - val_loss: 1.5841 - val_accuracy: 0.9645\n",
            "341/341 [==============================] - 564s 2s/step - loss: 1.8817 - accuracy: 0.8862\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 299, 299, 3)]     0         \n",
            "                                                                 \n",
            " sequential (Sequential)     (None, 299, 299, 3)       0         \n",
            "                                                                 \n",
            " inception_v3 (Functional)   (None, 8, 8, 2048)        21802784  \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 2048)             0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1024)              2098176   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               262400    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 4)                 1028      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 24,164,388\n",
            "Trainable params: 2,361,604\n",
            "Non-trainable params: 21,802,784\n",
            "_________________________________________________________________\n",
            "Epoch 13/24\n",
            "1374/1374 [==============================] - 578s 408ms/step - loss: 1.5665 - accuracy: 0.9624 - val_loss: 1.5128 - val_accuracy: 0.9848\n",
            "Epoch 14/24\n",
            "1374/1374 [==============================] - 561s 408ms/step - loss: 1.4999 - accuracy: 0.9895 - val_loss: 1.4768 - val_accuracy: 0.9953\n",
            "Epoch 15/24\n",
            "1374/1374 [==============================] - 581s 423ms/step - loss: 1.4728 - accuracy: 0.9974 - val_loss: 1.4640 - val_accuracy: 0.9965\n",
            "Epoch 16/24\n",
            "1374/1374 [==============================] - 564s 411ms/step - loss: 1.4562 - accuracy: 0.9988 - val_loss: 1.4629 - val_accuracy: 0.9924\n",
            "Epoch 17/24\n",
            "1374/1374 [==============================] - 561s 408ms/step - loss: 1.4438 - accuracy: 0.9997 - val_loss: 1.4428 - val_accuracy: 0.9953\n",
            "Epoch 18/24\n",
            "1374/1374 [==============================] - 561s 409ms/step - loss: 1.4296 - accuracy: 1.0000 - val_loss: 1.4262 - val_accuracy: 0.9965\n",
            "Epoch 19/24\n",
            "1374/1374 [==============================] - 560s 408ms/step - loss: 1.4109 - accuracy: 1.0000 - val_loss: 1.4073 - val_accuracy: 0.9971\n",
            "Epoch 20/24\n",
            "1374/1374 [==============================] - 556s 405ms/step - loss: 1.3933 - accuracy: 0.9994 - val_loss: 1.3901 - val_accuracy: 0.9971\n",
            "Epoch 21/24\n",
            "1374/1374 [==============================] - 577s 420ms/step - loss: 1.3779 - accuracy: 0.9994 - val_loss: 1.3750 - val_accuracy: 0.9971\n",
            "Epoch 22/24\n",
            "1374/1374 [==============================] - 555s 404ms/step - loss: 1.3619 - accuracy: 0.9997 - val_loss: 1.3553 - val_accuracy: 0.9983\n",
            "Epoch 23/24\n",
            "1374/1374 [==============================] - 557s 406ms/step - loss: 1.3386 - accuracy: 1.0000 - val_loss: 1.3299 - val_accuracy: 0.9965\n",
            "Epoch 24/24\n",
            "1374/1374 [==============================] - 559s 407ms/step - loss: 1.3028 - accuracy: 1.0000 - val_loss: 1.2845 - val_accuracy: 0.9971\n",
            "341/341 [==============================] - 64s 187ms/step - loss: 1.8998 - accuracy: 0.9331\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 299, 299, 3)]     0         \n",
            "                                                                 \n",
            " sequential (Sequential)     (None, 299, 299, 3)       0         \n",
            "                                                                 \n",
            " inception_v3 (Functional)   (None, 8, 8, 2048)        21802784  \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 2048)             0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1024)              2098176   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               262400    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 4)                 1028      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 24,164,388\n",
            "Trainable params: 24,112,740\n",
            "Non-trainable params: 51,648\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#Model\n",
        "\n",
        "model_path = pathlib.Path('/content/drive/MyDrive/archiveX3/SavedBaseModel.h5')\n",
        "\n",
        "base_model = tf.keras.models.load_model(model_path)                 #Loading base_model\n",
        "\n",
        "base_model.trainable = False                                        # Setting the model as non-trainable\n",
        "\n",
        "rescaling = tf.keras.Sequential([                                        \n",
        "  tf.keras.layers.Rescaling(scale=1 / 127.5, offset=-1)             # Rescaling to (1, -1) range required for inceptionV3 model\n",
        "])\n",
        "augmentation = tf.keras.Sequential([                                # Applying augmentations o the images\n",
        "   tf.keras.layers.RandomFlip(\"horizontal\"),\n",
        "   tf.keras.layers.RandomRotation(0.1)\n",
        "])\n",
        "\n",
        "inputs = tf.keras.Input(shape=(299, 299, 3))\n",
        "x = augmentation(inputs)\n",
        "x = rescaling(x)\n",
        "x = base_model(x)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = tf.keras.layers.Dense(1024, activation='ELU', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)     # Neurons numbers and activation functions based on testing and choosing the one with best results\n",
        "x = tf.keras.layers.Dropout(0.2)(x)\n",
        "# x = tf.keras.layers.Dense(512, activation='ELU', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)     # Regularizing and Dropout to avoid overfitting\n",
        "# x = tf.keras.layers.Dropout(0.2)(x)\n",
        "# x = tf.keras.layers.Dense(512, activation='ELU', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
        "# x = tf.keras.layers.Dropout(0.2)(x)\n",
        "x = tf.keras.layers.Dense(256, activation='ELU', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
        "x = tf.keras.layers.Dropout(0.2)(x)\n",
        "outputs = tf.keras.layers.Dense(4, activation='softmax')(x)                   # \"softmax\" in the final layer for decision making\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "\n",
        "model.compile(\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate = 0.00001),        # compiling with low learning rate\n",
        "    loss=tf.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics=['accuracy'],\n",
        "    run_eagerly = True)                                               \n",
        "\n",
        "model.fit(                                                               # fitting the whole model for non-trainable base\n",
        "    dataset_path,\n",
        "    epochs=12,   \n",
        "    validation_data = dataset_path_val)\n",
        "    #verbose = 1)\n",
        "\n",
        "\n",
        "model.evaluate(dataset_path_test, batch_size=5, verbose=1)               # evaluating using the test dataset \n",
        "\n",
        "model.summary()\n",
        "\n",
        "base_model.trainable = True                                           # switching the base_model to trainable\n",
        "\n",
        "for layer in base_model.layers:                                       # Swtching all batchnormalization layer of the base_model to non-trainable to not lose weights\n",
        "  if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate = 0.000001),    # compiling the model with a trainable base_model\n",
        "    loss=tf.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics=['accuracy'],\n",
        "    run_eagerly = True)\n",
        "\n",
        "model.fit(                                                            # fitting for another 10 epochs starting where the non-trainable ended\n",
        "    dataset_path,\n",
        "    epochs=24,         \n",
        "    initial_epoch=12,                \n",
        "    validation_data = dataset_path_val)\n",
        "    #verbose = 1)\n",
        "\n",
        "model.evaluate(dataset_path_test, batch_size=5, verbose=1)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# saving_path = pathlib.Path('/content/drive/MyDrive/archiveX3/SavedModelWithFT/')\n",
        "\n",
        "# tf.keras.models.save_model(model,                                     # saving the fully trained model\n",
        "#                            saving_path,\n",
        "#                            overwrite=True,\n",
        "#                            save_format='tf'\n",
        "#                            )"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Transfer.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.7 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "d4de0671d8054c88a8842951ed8f6115b974e2e5b39cbc2553be5a6678282e63"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}