{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\\\"https://colab.research.google.com/github/Samir-atra/CancerDetector/blob/main/Cancer_Detector/Transfer.ipynb\\\" target=\\\"_parent\\\"><img src=\\\"https://colab.research.google.com/assets/colab-badge.svg\\\" alt=\\\"Open In Colab\\\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goYGY5wRTiyY",
        "outputId": "ed42a1b1-5916-4308-dedb-46cc1651a511"
      },
      "outputs": [],
      "source": [
        "# 1. Imports and Setup\n",
        "# --------------------\n",
        "# This cell installs and imports the necessary libraries for the project.\n",
        "\n",
        "!pip install keras_tuner -q\n",
        "import tensorflow as tf\n",
        "import keras_tuner\n",
        "import numpy as np\n",
        "import os\n",
        "import pathlib\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime\n",
        "import tensorboard\n",
        "import IPython\n",
        "import sklearn\n",
        "import cv2\n",
        "import sys\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eITYDZ-iTt6h",
        "outputId": "6e2ba332-7c39-4b54-e62b-2efdb555aaa2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\\n"
          ]
        }
      ],
      "source": [
        "# 2. Mount Google Drive\n",
        "# ---------------------\n",
        "# Mount Google Drive to access the dataset, which is stored there.\n",
        "# This is necessary when running the notebook in Google Colab.\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Axnn0rKHT05-",
        "outputId": "7b2bef97-5540-49cb-82b9-2ff2cc0dbdd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 8582 files belonging to 4 classes.\\n",
            "Using 6866 files for training.\\n",
            "Found 8582 files belonging to 4 classes.\\n",
            "Using 1716 files for validation.\\n",
            "Found 1705 files belonging to 4 classes.\\n",
            "time elapsed =  32.22160363197327\\n"
          ]
        }
      ],
      "source": [
        "# 3. Dataset Loading\n",
        "# ------------------\n",
        "# Load the training, validation, and testing datasets from Google Drive.\n",
        "\n",
        "data_path = pathlib.Path('/content/drive/MyDrive/archiveX3/Training/')\n",
        "data_path_test = pathlib.Path('/content/drive/MyDrive/archiveX3/Testing/')\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "start = time.time()\n",
        "# Create the training and validation datasets.\n",
        "dataset_path, dataset_path_val = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_path,\n",
        "    labels='inferred',\n",
        "    validation_split=0.2,\n",
        "    subset='both',\n",
        "    seed=1,\n",
        "    batch_size=5,\n",
        "    image_size=(299, 299), # Image size must match InceptionV3 input.\n",
        "    color_mode=\"rgb\",\n",
        "    shuffle=True)\n",
        "\n",
        "# Create the testing dataset.\n",
        "dataset_path_test = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_path_test,\n",
        "    labels='inferred',\n",
        "    seed=3,\n",
        "    batch_size=5,\n",
        "    image_size=(299, 299),\n",
        "    color_mode=\"rgb\",\n",
        "    shuffle=True)\n",
        "\n",
        "end = time.time()\n",
        "print(f\"Time elapsed for data loading: {end - start:.2f} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tYCnSnGuT4yF"
      },
      "outputs": [],
      "source": [
        "# 4. Performance Optimization (Commented Out)\n",
        "# -------------------------------------------\n",
        "# Caching and prefetching can be enabled for faster training.\n",
        "\n",
        "# AUTOTUNE = tf.data.AUTOTUNE\n",
        "# dataset_path = dataset_path.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "# dataset_path_val = dataset_path_val.cache().prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rTTllaXT-RO",
        "outputId": "b88bafad-e9a3-41fb-8423-42758107ff40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\\n",
            "87910968/87910968 [==============================] - 5s 0us/step\\n"
          ]
        }
      ],
      "source": [
        "# 5. Load Base Model\n",
        "# ------------------\n",
        "# Download the InceptionV3 model, pre-trained on ImageNet.\n",
        "# `include_top=False` removes the final classification layer.\n",
        "\n",
        "base_model = tf.keras.applications.inception_v3.InceptionV3(\n",
        "    input_shape=(299, 299, 3),\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZVb7DPSUCc7",
        "outputId": "fcb19b69-0139-4bb2-a2fb-dfb6efe0d9ef"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\\n"
          ]
        }
      ],
      "source": [
        "# 6. Save Base Model\n",
        "# ------------------\n",
        "# Save the downloaded base model to avoid re-downloading it every time.\n",
        "\n",
        "saving_path = pathlib.Path('/content/drive/MyDrive/archiveX3/SavedBaseModel.h5')\n",
        "base_model.save(saving_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ToB-CteSUGro",
        "outputId": "08ce05b9-980e-48d9-bb63-650ea09d259f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\\n",
            "1374/1374 [==============================] - 2010s 1s/step - loss: 0.5756 - accuracy: 0.7830 - val_loss: 0.4003 - val_accuracy: 0.8625\\n",
            "Epoch 2/15\\n",
            "1374/1374 [==============================] - 486s 354ms/step - loss: 0.3808 - accuracy: 0.8602 - val_loss: 0.3462 - val_accuracy: 0.8759\\n",
            "Epoch 3/15\\n",
            "1374/1374 [==============================] - 488s 355ms/step - loss: 0.3311 - accuracy: 0.8793 - val_loss: 0.2980 - val_accuracy: 0.8887\\n",
            "Epoch 4/15\\n",
            "1374/1374 [==============================] - 493s 359ms/step - loss: 0.3019 - accuracy: 0.8865 - val_loss: 0.2656 - val_accuracy: 0.9091\\n",
            "Epoch 5/15\\n",
            "1374/1374 [==============================] - 493s 359ms/step - loss: 0.2756 - accuracy: 0.9002 - val_loss: 0.2547 - val_accuracy: 0.9108\\n",
            "Epoch 6/15\\n",
            "1374/1374 [==============================] - 489s 356ms/step - loss: 0.2570 - accuracy: 0.9049 - val_loss: 0.2322 - val_accuracy: 0.9184\\n",
            "Epoch 7/15\\n",
            "1374/1374 [==============================] - 489s 356ms/step - loss: 0.2499 - accuracy: 0.9093 - val_loss: 0.2566 - val_accuracy: 0.9073\\n",
            "Epoch 8/15\\n",
            "1374/1374 [==============================] - 489s 356ms/step - loss: 0.2439 - accuracy: 0.9129 - val_loss: 0.2070 - val_accuracy: 0.9318\\n",
            "Epoch 9/15\\n",
            "1374/1374 [==============================] - 487s 354ms/step - loss: 0.2339 - accuracy: 0.9160 - val_loss: 0.2021 - val_accuracy: 0.9301\\n",
            "Epoch 10/15\\n",
            "1374/1374 [==============================] - 492s 358ms/step - loss: 0.2230 - accuracy: 0.9155 - val_loss: 0.1935 - val_accuracy: 0.9371\\n",
            "Epoch 11/15\\n",
            "1374/1374 [==============================] - 492s 358ms/step - loss: 0.2191 - accuracy: 0.9224 - val_loss: 0.1949 - val_accuracy: 0.9330\\n",
            "Epoch 12/15\\n",
            "1374/1374 [==============================] - 487s 354ms/step - loss: 0.2122 - accuracy: 0.9219 - val_loss: 0.2010 - val_accuracy: 0.9312\\n",
            "Epoch 13/15\\n",
            "1374/1374 [==============================] - 477s 347ms/step - loss: 0.2076 - accuracy: 0.9240 - val_loss: 0.2446 - val_accuracy: 0.8980\\n",
            "Epoch 14/15\\n",
            "1374/1374 [==============================] - 480s 349ms/step - loss: 0.1942 - accuracy: 0.9323 - val_loss: 0.1748 - val_accuracy: 0.9429\\n",
            "Epoch 15/15\\n",
            "1374/1374 [==============================] - 478s 348ms/step - loss: 0.1939 - accuracy: 0.9286 - val_loss: 0.1746 - val_accuracy: 0.9382\\n",
            "341/341 [==============================] - 551s 2s/step - loss: 0.4692 - accuracy: 0.8522\\n",
            "Model: \\\"model\\\"\\n",
            "_________________________________________________________________\\n",
            " Layer (type)                Output Shape              Param #   \\n",
            "=================================================================\\n",
            " input_2 (InputLayer)        [(None, 299, 299, 3)]     0         \\n",
            "                                                                 \\n",
            " sequential_1 (Sequential)   (None, 299, 299, 3)       0         \\n",
            "                                                                 \\n",
            " sequential (Sequential)     (None, 299, 299, 3)       0         \\n",
            "                                                                 \\n",
            " inception_v3 (Functional)   (None, 8, 8, 2048)        21802784  \\n",
            "                                                                 \\n",
            " global_average_pooling2d (G  (None, 2048)             0         \\n",
            " lobalAveragePooling2D)                                          \\n",
            "                                                                 \\n",
            " dense (Dense)               (None, 4)                 8196      \\n",
            "                                                                 \\n",
            "=================================================================\\n",
            "Total params: 21,810,980\\n",
            "Trainable params: 8,196\\n",
            "Non-trainable params: 21,802,784\\n",
            "_________________________________________________________________\\n",
            "341/341 [==============================] - 63s 184ms/step - loss: 0.4692 - accuracy: 0.8522\\n",
            "Model: \\\"model\\\"\\n",
            "_________________________________________________________________\\n",
            " Layer (type)                Output Shape              Param #   \\n",
            "=================================================================\\n",
            " input_2 (InputLayer)        [(None, 299, 299, 3)]     0         \\n",
            "                                                                 \\n",
            " sequential_1 (Sequential)   (None, 299, 299, 3)       0         \\n",
            "                                                                 \\n",
            " sequential (Sequential)     (None, 299, 299, 3)       0         \\n",
            "                                                                 \\n",
            " inception_v3 (Functional)   (None, 8, 8, 2048)        21802784  \\n",
            "                                                                 \\n",
            " global_average_pooling2d (G  (None, 2048)             0         \\n",
            " lobalAveragePooling2D)                                          \\n",
            "                                                                 \\n",
            " dense (Dense)               (None, 4)                 8196      \\n",
            "                                                                 \\n",
            "=================================================================\\n",
            "Total params: 21,810,980\\n",
            "Trainable params: 21,759,332\\n",
            "Non-trainable params: 51,648\\n",
            "_________________________________________________________________\\n"
          ]
        }
      ],
      "source": [
        "# 7. Transfer Learning and Fine-Tuning\n",
        "# --------------------------------------\n",
        "# This cell implements the core logic for transfer learning.\n",
        "# The process involves two main stages:\n",
        "#   1. Feature Extraction: Train only the new classification head on top of the frozen base model.\n",
        "#   2. Fine-Tuning: Unfreeze some layers of the base model and train the entire model with a very low learning rate.\n",
        "\n",
        "# Load the saved base model.\n",
        "model_path = pathlib.Path('/content/drive/MyDrive/archiveX3/SavedBaseModel.h5')\n",
        "base_model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "# --- Stage 1: Feature Extraction ---\n",
        "base_model.trainable = False # Freeze the base model.\n",
        "\n",
        "# Define preprocessing and augmentation layers.\n",
        "rescaling = tf.keras.Sequential([\n",
        "    tf.keras.layers.Rescaling(scale=1 / 127.5, offset=-1) # Rescale to [-1, 1] for InceptionV3.\n",
        "])\n",
        "augmentation = tf.keras.Sequential([\n",
        "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
        "    tf.keras.layers.RandomRotation(0.1)\n",
        "])\n",
        "\n",
        "# Build the final model by adding a new classification head.\n",
        "inputs = tf.keras.Input(shape=(299, 299, 3))\n",
        "x = augmentation(inputs)\n",
        "x = rescaling(x)\n",
        "x = base_model(x, training=False)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "outputs = tf.keras.layers.Dense(4, activation='softmax')(x)\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# The following section for hyperparameter tuning with Keras Tuner is commented out.\n",
        "# It seems the author has already found a good learning rate.\n",
        "# def build_model(hp):\n",
        "#     ...\n",
        "#     return model\n",
        "# tuner = keras_tuner.RandomSearch(...)\n",
        "# tuner.search(...)\n",
        "\n",
        "# Compile the model for the feature extraction phase.\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005670323757088328),\n",
        "    loss=tf.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics=['accuracy'],\n",
        "    run_eagerly=True)\n",
        "\n",
        "# Train the model (only the new head).\n",
        "model.fit(\n",
        "    dataset_path,\n",
        "    epochs=15,\n",
        "    validation_data=dataset_path_val)\n",
        "\n",
        "# Evaluate the model after the first stage.\n",
        "model.evaluate(dataset_path_test, batch_size=5, verbose=1)\n",
        "model.summary()\n",
        "\n",
        "# --- Stage 2: Fine-Tuning (Commented Out) ---\n",
        "# In this stage, the base model is unfrozen to train the entire network.\n",
        "\n",
        "base_model.trainable = True\n",
        "\n",
        "# It's important to freeze BatchNormalization layers when fine-tuning.\n",
        "for layer in base_model.layers:\n",
        "    if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
        "        layer.trainable = False\n",
        "\n",
        "# Re-compile the model with a very low learning rate for fine-tuning.\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.000001),\n",
        "    loss=tf.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics=['accuracy'],\n",
        "    run_eagerly=True)\n",
        "\n",
        "# The fine-tuning training is commented out, but would typically be run here.\n",
        "# model.fit(\n",
        "#     dataset_path,\n",
        "#     epochs=30,\n",
        "#     initial_epoch=15, # Continue from the previous training.\n",
        "#     validation_data=dataset_path_val)\n",
        "\n",
        "# Evaluate the model after fine-tuning.\n",
        "model.evaluate(dataset_path_test, batch_size=5, verbose=1)\n",
        "model.summary()\n",
        "\n",
        "# The code for saving the final fine-tuned model is also commented out.\n",
        "# saving_path = pathlib.Path('/content/drive/MyDrive/archiveX3/SavedModelWithFT/')\n",
        "# tf.keras.models.save_model(model, saving_path, ...)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
