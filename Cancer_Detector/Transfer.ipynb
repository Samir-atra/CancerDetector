{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Samir-atra/CancerDetector/blob/main/Cancer_Detector/Transfer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "goYGY5wRTiyY"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "\n",
        "!pip install keras_tuner -q\n",
        "import tensorflow as tf\n",
        "import keras_tuner\n",
        "import numpy as np\n",
        "import os\n",
        "import pathlib\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime\n",
        "import tensorboard\n",
        "import IPython\n",
        "import sklearn\n",
        "import cv2\n",
        "import sys\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mounting google drive for training in google co lab\n",
        "\n",
        "from google.colab import drive             \n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "eITYDZ-iTt6h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87f3eaff-d812-4210-e0d6-1aca274f8267"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset loading\n",
        "\n",
        "data_path = pathlib.Path('/content/drive/MyDrive/archiveX3/Training/')\n",
        "\n",
        "data_path_test = pathlib.Path('/content/drive/MyDrive/archiveX3/Testing/')\n",
        "AUTOTUNE=tf.data.AUTOTUNE\n",
        "\n",
        "start = time.time()\n",
        "dataset_path = tf.keras.utils.image_dataset_from_directory(        # Training dataset\n",
        "    data_path,\n",
        "    labels= 'inferred',\n",
        "    validation_split=0.2,\n",
        "    subset='training',\n",
        "    seed= 1,\n",
        "    batch_size=5,\n",
        "    image_size=(299, 299),\n",
        "    color_mode=\"rgb\",\n",
        "    shuffle=True)#.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "dataset_path_val = tf.keras.utils.image_dataset_from_directory(      #Validation dataset\n",
        "    data_path,\n",
        "    labels= 'inferred',\n",
        "    validation_split=0.2,\n",
        "    subset='validation',\n",
        "    seed= 2,\n",
        "    batch_size=5,\n",
        "    image_size=(299, 299),\n",
        "    color_mode=\"rgb\",\n",
        "    shuffle=True)#.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "dataset_path_test = tf.keras.utils.image_dataset_from_directory(      # Testing dataset\n",
        "    data_path_test,\n",
        "    labels= 'inferred',\n",
        "    seed= 3,\n",
        "    batch_size=5,\n",
        "    image_size=(299, 299),\n",
        "    color_mode=\"rgb\",\n",
        "    shuffle=True)#.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "end = time.time()\n",
        "print(\"time elapsed = \", (end - start))"
      ],
      "metadata": {
        "id": "Axnn0rKHT05-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9b7c110-b968-4db3-ce57-f359e994befb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8582 files belonging to 4 classes.\n",
            "Using 6866 files for training.\n",
            "Found 8582 files belonging to 4 classes.\n",
            "Using 1716 files for validation.\n",
            "Found 1705 files belonging to 4 classes.\n",
            "time elapsed =  31.64029574394226\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# catch and prefetch for shorter training time\n",
        "\n",
        "# AUTOTUNE=tf.data.AUTOTUNE\n",
        "# dataset_path = dataset_path.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "# dataset_path_val = dataset_path_val.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "tYCnSnGuT4yF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# downloading the weights oft the base model\n",
        "\n",
        "base_model = tf.keras.applications.inception_v3.InceptionV3(\n",
        "    input_shape = (299, 299, 3),\n",
        "    include_top = False, \n",
        "    weights = \"imagenet\"                  \n",
        ")"
      ],
      "metadata": {
        "id": "0rTTllaXT-RO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c57bcb41-ce03-4965-d7d7-fcb78c66361b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87910968/87910968 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#saving the downloaded base_model \n",
        "\n",
        "saving_path = pathlib.Path('/content/drive/MyDrive/archiveX3/SavedBaseModel.h5')\n",
        "\n",
        "base_model.save(saving_path)"
      ],
      "metadata": {
        "id": "FZVb7DPSUCc7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6f95cd5-b7d5-4fbe-eed0-503eddef59d7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model\n",
        "\n",
        "model_path = pathlib.Path('/content/drive/MyDrive/archiveX3/SavedBaseModel.h5')\n",
        "\n",
        "base_model = tf.keras.models.load_model(model_path)                 #Loading base_model\n",
        "\n",
        "base_model.trainable = False                                        # Setting the model as non-trainable\n",
        "\n",
        "rescaling = tf.keras.Sequential([                                        \n",
        "  tf.keras.layers.Rescaling(scale=1 / 127.5, offset=-1)             # Rescaling to (1, -1) range required for inceptionV3 model\n",
        "])\n",
        "augmentation = tf.keras.Sequential([                                # Applying augmentations o the images\n",
        "   tf.keras.layers.RandomFlip(\"horizontal\"),\n",
        "   tf.keras.layers.RandomRotation(0.1)\n",
        "])\n",
        "\n",
        "# def build_model(hp):\n",
        "\n",
        "inputs = tf.keras.Input(shape=(299, 299, 3))\n",
        "x = augmentation(inputs)\n",
        "x = rescaling(x)\n",
        "x = base_model(x, training=False)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "# x = tf.keras.layers.Dense(1024, activation='ELU', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)     # Neurons numbers and activation functions based on testing and choosing the one with best results\n",
        "# x = tf.keras.layers.Dropout(0.2)(x)\n",
        "# x = tf.keras.layers.Dense(512, activation='ELU', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)     # Regularizing and Dropout to avoid overfitting\n",
        "# x = tf.keras.layers.Dropout(0.2)(x)\n",
        "# x = tf.keras.layers.Dense(512, activation='ELU', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
        "# x = tf.keras.layers.Dropout(0.2)(x)\n",
        "# x = tf.keras.layers.Dense(256, activation='ELU', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
        "# x = tf.keras.layers.Dropout(0.2)(x)\n",
        "outputs = tf.keras.layers.Dense(4, activation='softmax')(x)                   # \"softmax\" in the final layer for decision making\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# learning_rate = hp.Float(\"lr\", min_value=1e-5, max_value=1e-3, sampling=\"log\")\n",
        "\n",
        "model.compile(\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate = 0.00050233),        # compiling with low learning rate\n",
        "    loss=tf.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics=['accuracy'],\n",
        "    run_eagerly = True)                                               \n",
        "  \n",
        "#  return model \n",
        "\n",
        "# build_model(keras_tuner.HyperParameters())\n",
        "\n",
        "# tuner = keras_tuner.RandomSearch(\n",
        "#     hypermodel=build_model,\n",
        "#     objective=\"val_accuracy\",\n",
        "#     max_trials=3,\n",
        "#     executions_per_trial=2,\n",
        "#     overwrite=True,\n",
        "#     directory=\"/content/drive/MyDrive/Transfer\",\n",
        "#     project_name=\"Tuner\",\n",
        "# )\n",
        "\n",
        "# tuner.search_space_summary()\n",
        "\n",
        "# tuner.search(dataset_path, epochs=5, validation_data = dataset_path_val)\n",
        "\n",
        "# tuner.results_summary()\n",
        "\n",
        "\n",
        "model.fit(                                                               # fitting the whole model for non-trainable base\n",
        "    dataset_path,\n",
        "    epochs=15,   \n",
        "    validation_data = dataset_path_val)\n",
        "    #verbose = 1)\n",
        "\n",
        "\n",
        "model.evaluate(dataset_path_test, batch_size=5, verbose=1)               # evaluating using the test dataset \n",
        "\n",
        "model.summary()\n",
        "\n",
        "base_model.trainable = True                                           # switching the base_model to trainable\n",
        "\n",
        "for layer in base_model.layers:                                       # Swtching all batchnormalization layer of the base_model to non-trainable to not lose weights\n",
        "  if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate = 0.00001),    # compiling the model with a trainable base_model\n",
        "    loss=tf.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics=['accuracy'],\n",
        "    run_eagerly = True)\n",
        "\n",
        "# model.fit(                                                            # fitting for another 10 epochs starting where the non-trainable ended\n",
        "#     dataset_path,\n",
        "#     epochs=30,         \n",
        "#     initial_epoch=15,                \n",
        "#     validation_data = dataset_path_val)\n",
        "    #verbose = 1)\n",
        "\n",
        "model.evaluate(dataset_path_test, batch_size=5, verbose=1)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# saving_path = pathlib.Path('/content/drive/MyDrive/archiveX3/SavedModelWithFT/')\n",
        "\n",
        "# tf.keras.models.save_model(model,                                     # saving the fully trained model\n",
        "#                            saving_path,\n",
        "#                            overwrite=True,\n",
        "#                            save_format='tf'\n",
        "#                            )"
      ],
      "metadata": {
        "id": "ToB-CteSUGro",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea0d3248-0cdf-4146-edfa-a3768ffe0096"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 2 Complete [01h 23m 40s]\n",
            "val_accuracy: 0.9111305177211761\n",
            "\n",
            "Best val_accuracy So Far: 0.9111305177211761\n",
            "Total elapsed time: 02h 58m 28s\n",
            "\n",
            "Search: Running Trial #3\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "3.9869e-05        |0.00050233        |lr\n",
            "\n",
            "Epoch 1/5\n",
            "1374/1374 [==============================] - 523s 380ms/step - loss: 1.0540 - accuracy: 0.5942 - val_loss: 0.8026 - val_accuracy: 0.7436\n",
            "Epoch 2/5\n",
            "1374/1374 [==============================] - 501s 365ms/step - loss: 0.7079 - accuracy: 0.7716 - val_loss: 0.6376 - val_accuracy: 0.7995\n",
            "Epoch 3/5\n",
            "1374/1374 [==============================] - 497s 362ms/step - loss: 0.5919 - accuracy: 0.8051 - val_loss: 0.5623 - val_accuracy: 0.8199\n",
            "Epoch 4/5\n",
            "1374/1374 [==============================] - 496s 361ms/step - loss: 0.5318 - accuracy: 0.8248 - val_loss: 0.5164 - val_accuracy: 0.8322\n",
            "Epoch 5/5\n",
            "1374/1374 [==============================] - 490s 357ms/step - loss: 0.4933 - accuracy: 0.8392 - val_loss: 0.4837 - val_accuracy: 0.8438\n",
            "Epoch 1/5\n",
            "1374/1374 [==============================] - 493s 358ms/step - loss: 1.0301 - accuracy: 0.6103 - val_loss: 0.8045 - val_accuracy: 0.7348\n",
            "Epoch 2/5\n",
            "1374/1374 [==============================] - 497s 361ms/step - loss: 0.6963 - accuracy: 0.7791 - val_loss: 0.6426 - val_accuracy: 0.7821\n",
            "Epoch 3/5\n",
            " 555/1374 [===========>..................] - ETA: 4:17 - loss: 0.6070 - accuracy: 0.7978"
          ]
        }
      ]
    }
  ]
}