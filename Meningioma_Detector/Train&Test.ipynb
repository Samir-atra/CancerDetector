{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL.Image\n",
    "from PIL import ImageOps\n",
    "import PIL\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import tensorboard\n",
    "import IPython\n",
    "import sklearn\n",
    "import cv2\n",
    "import subprocess\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset loading\n",
    "\n",
    "data_path = pathlib.Path('/home/samer/Documents/Programming/AI50xIraq/Cancerdetection/archivecopy/Training/')\n",
    "data_path_test = pathlib.Path('/home/samer/Documents/Programming/AI50xIraq/Cancerdetection/archivecopy/Testing/')\n",
    "\n",
    "dataset_path = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_path,\n",
    "    labels= 'inferred',\n",
    "    validation_split=0.2,\n",
    "    subset='training',\n",
    "    seed= 1,\n",
    "    batch_size=5,\n",
    "    image_size=(180, 180),\n",
    "    color_mode=\"grayscale\",\n",
    "    shuffle=True)\n",
    "\n",
    "dataset_path_val = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_path,\n",
    "    labels= 'inferred',\n",
    "    validation_split=0.2,\n",
    "    subset='validation',\n",
    "    seed= 2,\n",
    "    batch_size=5,\n",
    "    image_size=(180, 180),\n",
    "    color_mode=\"grayscale\",\n",
    "    shuffle=True)\n",
    "\n",
    "dataset_path_test = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_path_test,\n",
    "    labels= 'inferred',\n",
    "    seed= 3,\n",
    "    batch_size=5,\n",
    "    image_size=(180, 180),\n",
    "    color_mode=\"grayscale\",\n",
    "    shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch and prefetch\n",
    "AUTOTUNE=tf.data.AUTOTUNE\n",
    "dataset_path = dataset_path.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "dataset_path_val = dataset_path_val.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counts and visualisations could be replaced by tensorboard mostly\n",
    "\n",
    "class_names = dataset_path.class_names\n",
    "print(class_names)\n",
    "\n",
    "data_path = pathlib.Path('/home/samer/Documents/Programming/AI50xIraq/Cancerdetection/archivecopy/Training')\n",
    "data_dir = pathlib.Path(data_path)\n",
    "image_count = len(list(data_path.glob('*/*.jpg')))\n",
    "print(image_count)\n",
    "\n",
    "plt.figure(figsize=(1, 2))\n",
    "for images, labels in dataset_path.take(1):\n",
    "   for i in range(2):\n",
    "       ax = plt.subplot(1, 2, i+1)\n",
    "       ax.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "       plt.title(class_names[labels[i]])\n",
    "       plt.axis(\"off\")\n",
    "   plt.show()\n",
    "        print(\"hello\")\n",
    "x= 0\n",
    "for image_batch, labels_batch in dataset_path:\n",
    "   print(image_batch.shape)\n",
    "   print(labels_batch.shape)\n",
    "   x = x+1\n",
    "   continue\n",
    "print(x)\n",
    "\n",
    "image, label= next(iter(dataset_path.take(1)))\n",
    "_ = plt.imshow(image.numpy().astype(\"uint8\"))\n",
    "_ = plt.title(get_label_name(label))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "\n",
    "num_classes = 2\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Resizing(60, 60),\n",
    "    tf.keras.layers.Rescaling(1./255),\n",
    "    tf.keras.layers.Conv2D(16, 3, activation='ELU', kernel_regularizer=tf.keras.regularizers.l2(0.001)),  \n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Dropout(0.2),                                                                         #DP1\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='ELU', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Dropout(0.2),                                                                         #DP2\n",
    "    tf.keras.layers.Conv2D(64, 3, activation='ELU', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Dropout(0.2),                                                                         #DP3\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='ELU', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    tf.keras.layers.Dropout(0.2),                                                                         #DP4\n",
    "    tf.keras.layers.Dense(128, activation='ELU', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    tf.keras.layers.Dropout(0.2),                                                                         #DP5\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "#########################################\n",
    "result = model(image)\n",
    "_ = plt.imshow(result)\n",
    "plt.show()\n",
    "                                                          #More visualisations\n",
    "plt.figure(figsize=(1, 1))\n",
    "for images, labels in dataset_path.take(1):\n",
    "   result = model(images[1])\n",
    "   print(result.numpy().min(), result.numpy().max())\n",
    "   _ = plt.imshow(result)\n",
    "   plt.show()\n",
    "#########################################\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.losses.SparseCategoricalCrossentropy(from_logits= True),\n",
    "    metrics=['accuracy','mse'])\n",
    "\n",
    "#TensorBoard\n",
    "log_dir= \"/home/samer/Documents/Programming/AI50xIraq/Cancerdetection/TBLog/\" + datetime.datetime.now().strftime(\"%Y%M%D-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir = log_dir, histogram_freq=1)\n",
    "\n",
    "#Save\n",
    "checkpoint_path = \"/home/samer/Documents/Programming/AI50xIraq/Cancerdetection/Checkpoints/cp-{epoch:04d}.ckpt\"\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, \n",
    "                                                 save_weights_only=True,\n",
    "                                                 #save_best_only=True, \n",
    "                                                 verbose=1,\n",
    "                                                 #save_freq=10\n",
    "                                                  )\n",
    "\n",
    "model.save_weights(checkpoint_path.format(epoch=0))\n",
    "\n",
    "model.fit(\n",
    "    dataset_path,\n",
    "    epochs=15,                                    \n",
    "    validation_data = dataset_path_val\n",
    "    callbacks =[tensorboard_callback,\n",
    "                 cp_callback\n",
    "                 ])\n",
    "\n",
    "model.evaluate(dataset_path_test, batch_size=5, verbose=2)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "saving_path = pathlib.Path('/home/samer/Documents/Programming/AI50xIraq/Cancerdetection/SavedModel/')\n",
    "\n",
    "tf.keras.models.save_model(model,\n",
    "                           saving_path,\n",
    "                           overwrite=True,\n",
    "                           save_format='tf'\n",
    "                           )\n",
    "\n",
    "#To load the model use:\n",
    "#loaded_model = tf.keras.models.load_model('/home/samer/Documents/Programming/AI50xIraq/Cancerdetection/SavedModel/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorboard\n",
    "\n",
    "# for clearing use: rm -rf /home/samer/Documents/Programming/AI50xIraq/Cancerdetection/TBLog/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Todo\n",
    "- use the dataset to train, validate and test.               (done)\n",
    "- use dropout to avoid overfitting.                          (done)\n",
    "- save a copy to load when deploying.                        (done)\n",
    "- deploy with tensorflow.js. or TFX                          (predictionful)\n",
    "- add some augmentation to expand the dataset.               (done)\n",
    "- add more classes to work on the full dataset.              (done)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Record\n",
    "- ELU + sigmoid around 98 val 97\n",
    "- ELU + softmax around 97 val 98 dips though but best yet"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4de0671d8054c88a8842951ed8f6115b974e2e5b39cbc2553be5a6678282e63"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
